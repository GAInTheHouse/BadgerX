{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"narrinterp.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"op5NcxbQBO5z","executionInfo":{"status":"ok","timestamp":1606285962334,"user_tz":360,"elapsed":28171,"user":{"displayName":"Collin FRINK","photoUrl":"","userId":"13914759981667661148"}},"outputId":"255dea96-df45-4529-b2e4-546872ce6387"},"source":["!apt-get install build-essential python3-dev python3-numpy libhdf4-dev -y\n","!pip install pyhdf\n","!pip install openturns\n","import pandas as pd\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import matplotlib.lines as mlines\n","import tables\n","import h5py\n","import numpy as np\n","import sys\n","from pyhdf.SD import SD, SDC\n","import pandas as pd\n","import time\n","import calendar\n","import matplotlib.pyplot as plt\n","import datetime\n","import os\n","import openturns as ot\n","import datetime\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/My Drive/BadgerX Data\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","build-essential is already the newest version (12.4ubuntu1).\n","python3-numpy is already the newest version (1:1.13.3-2ubuntu1).\n","python3-numpy set to manually installed.\n","python3-dev is already the newest version (3.6.7-1~18.04).\n","The following additional packages will be installed:\n","  libhdf4-0\n","Suggested packages:\n","  libhdf4-doc hdf4-tools\n","The following NEW packages will be installed:\n","  libhdf4-0 libhdf4-dev\n","0 upgraded, 2 newly installed, 0 to remove and 14 not upgraded.\n","Need to get 716 kB of archives.\n","After this operation, 3,154 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhdf4-0 amd64 4.2.13-2 [301 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhdf4-dev amd64 4.2.13-2 [415 kB]\n","Fetched 716 kB in 2s (317 kB/s)\n","Selecting previously unselected package libhdf4-0.\n","(Reading database ... 144793 files and directories currently installed.)\n","Preparing to unpack .../libhdf4-0_4.2.13-2_amd64.deb ...\n","Unpacking libhdf4-0 (4.2.13-2) ...\n","Selecting previously unselected package libhdf4-dev.\n","Preparing to unpack .../libhdf4-dev_4.2.13-2_amd64.deb ...\n","Unpacking libhdf4-dev (4.2.13-2) ...\n","Setting up libhdf4-0 (4.2.13-2) ...\n","Setting up libhdf4-dev (4.2.13-2) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Collecting pyhdf\n","  Using cached https://files.pythonhosted.org/packages/38/58/c0a756c2444c14fad7af6ef45f3d273b4320fefdb530de65d6373e204f93/pyhdf-0.10.2.tar.gz\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pyhdf\n","  Building wheel for pyhdf (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyhdf: filename=pyhdf-0.10.2-cp36-cp36m-linux_x86_64.whl size=255839 sha256=898c5be14c64560b961dc6203f10b630ada12f11a6886fb5f7917c0d6d05e735\n","  Stored in directory: /root/.cache/pip/wheels/6c/34/4c/25b83941b312940026288083fbcfba3679d21d0617e83846b5\n","Successfully built pyhdf\n","Installing collected packages: pyhdf\n","Successfully installed pyhdf-0.10.2\n","Requirement already satisfied: openturns in /usr/local/lib/python3.6/dist-packages (1.16)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1DebF_UxJ8HVlNU3YtYGSpTlwMstdY3sb/BadgerX Data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XIbJpZQeBSBG","executionInfo":{"status":"ok","timestamp":1606286033119,"user_tz":360,"elapsed":65488,"user":{"displayName":"Collin FRINK","photoUrl":"","userId":"13914759981667661148"}},"outputId":"900de1a5-f1f6-4b40-986e-b4a66b2cb989"},"source":["import csv\n","import numpy as np\n","\n","ave = np.array(list(csv.reader(open(\"narr2010ave.csv\"))), dtype=float)\n","for i in range(1, 10):\n","  temp = np.array(list(csv.reader(open(\"narr201\"+str(i) + \"ave.csv\"))),dtype=float)\n","  print(temp.shape)\n","  ave = np.concatenate((ave, temp), axis=0)\n","\n","\n","print(ave.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(365, 57600)\n","(366, 57600)\n","(365, 57600)\n","(365, 57600)\n","(365, 57600)\n","(366, 57600)\n","(365, 57600)\n","(365, 57600)\n","(365, 57600)\n","(3652, 57600)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":776},"id":"s697BA-QBeJr","executionInfo":{"status":"error","timestamp":1606286250078,"user_tz":360,"elapsed":73175,"user":{"displayName":"Collin FRINK","photoUrl":"","userId":"13914759981667661148"}},"outputId":"bcb216e2-30f3-42f3-965c-3e26c83bc2ab"},"source":["fin = []\n","ave = pd.DataFrame(ave)\n","\n","for day in range(3652):hum\n","  krig_data = ave.iloc[day]\n","  krig_data_train = np.where(hum != 0) #np.where(hum != 0)\n","  krig_data_test = np.where(hum == 0)\n","  krig_data_train = krig_data[krig_data_train[0]] #gets values\n","  krig_data_test = krig_data[krig_data_test[0]]\n","  lons = [krig_data_train.index[i] % 120 for i in range(len(krig_data_train))]\n","  lats = [(krig_data_train.index[i] - (krig_data_train.index[i] % 120)) / 120 for i in range(len(krig_data_train))]\n","  c = [np.array(i) for i in zip(lats, lons)]\n","  d = [[krig_data_train.iloc[i]] for i in range(len(krig_data_train))]\n","  coordinates_train = ot.Sample(c)\n","  aod_train = ot.Sample(d)\n","  inputDimension = 2\n","  basis = ot.ConstantBasisFactory(inputDimension).build()\n","  covarianceModel = ot.SquaredExponential([1.]*inputDimension, [1.0])\n","  algo = ot.KrigingAlgorithm(coordinates_train, aod_train, covarianceModel, basis)\n","  algo.run()\n","  result = algo.getResult()\n","  krigingMetamodel = result.getMetaModel()\n","  lons_test = [krig_data_test.index[i] % 120 for i in range(len(krig_data_test))]\n","  lats_test = [(krig_data_test.index[i] - (krig_data_test.index[i] % 120)) / 120 for i in range(len(krig_data_test))]\n","  c = [np.array(i) for i in zip(lats_test, lons_test)]\n","  kriged_data_pred = krigingMetamodel(c)\n","  kriged_data_pred = pd.Series(np.array(kriged_data_pred).reshape(-1))\n","  kriged_map_arr = np.zeros((120, 120))\n","\n","  for i in range(len(krig_data_test.index)):\n","    kriged_map_arr[(int)((krig_data_test.index[i] - (krig_data_test.index[i] % 120)) / 120), (int)(krig_data_test.index[i] % 120)] = kriged_data_pred[i]\n","    \n","  for i in range(len(krig_data_train.index)):\n","    kriged_map_arr[(int)((krig_data_train.index[i] - (krig_data_train.index[i] % 120)) / 120), (int)(krig_data_train.index[i] % 120)] = krig_data_train[krig_data_train.index[i]]\n","\n","  fin.append(kriged_map_arr)\n","  print(day)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-f4156f2a3a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mcovarianceModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSquaredExponential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKrigingAlgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maod_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovarianceModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mkrigingMetamodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMetaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/openturns/metamodel.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4945\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mopenturns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKrigingResult\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mstructure\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4946\u001b[0m         \"\"\"\n\u001b[0;32m-> 4947\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_metamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKrigingAlgorithm_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetInputSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ThHNcMx1E0sa"},"source":[""],"execution_count":null,"outputs":[]}]}